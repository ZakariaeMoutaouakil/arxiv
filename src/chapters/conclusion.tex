\section{Conclusion and Future Work}\label{sec:conclusion-and-future-work}
In this paper, we have presented novel techniques for improving the estimation of certified radii in randomized smoothing, leading to tighter bounds on certified test-set accuracy.
Our methods have demonstrated significant improvements on both CIFAR-10 and ImageNet datasets, showcasing the potential for more efficient and accurate certification of neural network robustness against adversarial perturbations.
While our results mark a substantial step forward in the field of adversarial robustness, they also open up several promising avenues for future research:
One particularly intriguing direction is the development of more efficient tricks for estimating certified radii in discrete domains.
In the continuous case, our work has highlighted the importance of tight confidence intervals for accurate estimation of certified radii, leaving the exploration of tighter confidence sequences and the development of new theoretical frameworks that provide rigorous backing for the tightness of these improved confidence intervals for future work.
By pursuing these lines of research, we hope to further narrow the gap between empirical performance and theoretical guarantees in randomized smoothing.
We leave for future the comparison between empirical certified radii (like those based on PGD attacks) and estimated certified radii.
